
<!doctype html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64375-4', 'auto');
  ga('send', 'pageview');
</script>
<head><meta charset="utf-8">
	<title>Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On (SCA 2020)</title>
	<meta name="title" content="Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On" />
	<meta name="description" content="Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On" />
	<meta http-equiv="content-type" content="text/html; charset=UTF-8">
	<meta name="viewport" content="initial-scale=1, maximum-scale=1">

	<link rel="shortcut icon" id="favicon" href="../../favicon.png"> 
	<meta name="author" content="Dan Casas">

	<!-- CSS -->
	<link rel="stylesheet" href="../../css/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="css/project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />

	<!-- Docs Bootstrap: getbootstrap.com -->
</head>
<!-- Els atributs del bodi son per que el menu reflexi el lloc on estas mentre fas scroll. El offset coincideix amb el padding-top del body -->

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>

<body id="dan" data-spy="scroll" data-target="#menu" data-offset="70">
	<!-- Les ID son per cada seccio, per que fagi scroll al fer click al menu, vindrien a ser links -->
	<section id="paper_title">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12" id="top">
				<h2><b>Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On</b></h2>	
				<h4 style="line-height:1.65;">Raquel Vidaurre, <a href="http://isantesteban.com" target="_blank" >Igor Santesteban</a>, <a href="http://www.elenagarces.es/">Elena Garces</a>, and <a href="http://dancasas.github.io" target="_blank" >Dan Casas</a><br/>
				<i>Computer Graphics Forum </br>Proc. of ACM SIGGRAPH Symposium on Computer Animation</i>, 2020</h4><br/><br/>
				<!--
				<iframe style="display: block; margin: auto;" width="560" height="315" src="https://www.youtube.com/embed/o2KJoAhEGg8" frameborder="0" allowfullscreen></iframe>
				-->
				<div class='embed-container'><iframe src='https://www.youtube.com/embed/f01Z2H5dG-g' frameborder='0' allowfullscreen></iframe></div>
			</div>
		</div>
	</section>
	<section id="abstract">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12" id="top">
				<h3>Abstract</h3>
				<p>We present a learning-based approach for virtual try-on applications based on a fully convolutional graph neural network. In contrast to existing data-driven models, which are trained for a specific garment or mesh topology, our fully convolutional model can cope with a large family of garments, represented as parametric predefined 2D panels with arbitrary mesh topology, including long dresses, shirts, and tight tops. Under the hood, our novel geometric deep learning approach learns to drape 3D garments by decoupling the three different sources of deformations that condition the fit of clothing: garment type, target body shape, and material. Specifically, we first learn a regressor that predicts the 3D drape of the input parametric garment when worn by a mean body shape. Then, after a mesh topology optimization step where we generate a sufficient level of detail for the input garment type, we further deform the mesh to reproduce deformations caused by the target body shape. Finally, we predict fine-scale details such as wrinkles that depend mostly on the garment material. We qualitatively and quantitatively demonstrate that our fully convolutional approach outperforms existing methods in terms of generalization capabilities and memory requirements, and therefore it opens the door to more general learning-based models for virtual try-on applications.</p>
			</div>
		</div>
	</section>
	<section id="files">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Files</h3>
				
				<ul>
					<li class="grid">
						<div class="griditem">
							<a href="contents/vidaurre_SCA2020.pdf" target="_blank" class="imageLink"><img src="contents/vidaurre_SCA2020_thumb.jpg"></a>
							<p><a href="contents/vidaurre_SCA2020.pdf" target="_blank">Paper(10MB)</a></p><br>
				  	</div>
					</li>
				</ul>
				<br>
			</div>
		</div>
	</section>
<br/>
	<section id="bibtex">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Citation</h3>
				<pre>@article {vidaurre2020virtualtryon,
    journal = {Computer Graphics Forum (Proc. SCA)},
    title = {{Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On}},
    author = {Vidaurre, Raquel and Santesteban, Igor and Garces, Elena and Casas, Dan},
    year = {2020}
}</pre>
				   
			</div>
		</div>
	</section>
	<br>
	<section id="images">
        <div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Description and Results</h3>
				<p>Our goal is to predict the accurate 3D draping of garments, worn by any body shape, for virtual try-on purposes. We put special emphasis on the ability to cope with a large variety of garments, a feature mostly ignored by existing works since it requires a model that can deal with varying topology input. To this end, we propose a fully convolutional graph neural network approach that is able to predict the nonrigid deformations of parametric garments with arbitrary mesh topology.</p> 
				<p>
					This is an example of 4 garments fitted into a large range of bodies, deformed with our approach. Notice how the wrinkles naturally match the expected behavior of the garment, and change for each shape-garment pair.
				</p>
				<img style="width: 100%; max-width: 720px; height: auto;" src="contents/vidaurre_SCA2020_clip01_x4.gif">
				<p>
					Under the hood, our novel geometric deep learning approach learns to drape 3D garments by decoupling the three different sources of deformations that condition the fit of clothing: garment type, target body shape, and material.
				</p>
				<a href="contents/pipeline.jpg"><img style="width: 100%; max-width: 720px; height: auto;" src="contents/pipeline.jpg"></a>
				<p>
					The regressor <i>R</i><sub>mean</sub> estimates the 3D mesh of the designed garment fitted into a mean body shape. Then, after a mesh topology optimization step to generate the optimal topology for the designed garment, regressors <i>R</i><sub>smooth</sub> and <i>R</i><sub>fine</sub> deform the mesh to reproduce deformations caused by the target body shape and material. Importantly, these regressors are implemented in a novel fully convolutional graph neural network (FCGNN) that is able to cope with any combination of garment, topology, and target body. Below we depict the architecture of <i>R</i><sub>smooth</sub> and <i>R</i><sub>fine</sub>, based on a U-Net and graph convolutions. 
				</p>
				<a href="contents/networks.jpg"><img style="width: 100%; max-width: 720px; height: auto;" src="contents/networks.jpg"></a>
				<p>
					Below we show a variety of our results visualized from an orbital camera.
				</p>
				<img style="width: 100%; max-width: 720px; height: auto;" src="contents/vidaurre_SCA2020_clip02_x2.gif">				
				<br/>
				<p>
					Our method is highly efficient and can be used in design applications where fast feedback is required. Below we show our  tool that allows to interactively manipulate the design parameters of the garment, and quickly visualize the fit onto arbitrary target bodies.
				</p>
				<img style="width: 100%; max-width: 720px; height: auto;" src="contents/vidaurre_clip03_merged.gif">				
				<br/>
            </div>
		</div>
	</section>
	<br>
	<section id="Acknowledgments">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Acknowledgments</h3>
				Igor Santesteban was supported by the Predoctoral Training Programme of the Department of Education of the Basque Government (PRE_2019_2_0104), and Elena Garces was supported by a Torres Quevedo Fellowship (PTQ2018-009868). The work was also funded in part by the Spanish Ministry of Science (project RTI2018-098694-B-I00 VizLearning).
			</div>
		</div>
	</section>
	<br>
	<section id="contact">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Contact</h3>
				Dan Casas â€“ dan.casas@urjc.es
			</div>
		</div>
	</section>
	<footer>
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<br/><br/><br/>
			</div>
		</div>
	</footer>
</body>
</html>
